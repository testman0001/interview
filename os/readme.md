## 进程与线程
### 理解进程
系统资源如cpu和io速度存在巨大差异，为了更合理地调度系统资源，例如在等待io时可以进行cpu计算，因此引申进程的概念，它是资源管理的基本单位
状态为几种：
1.New，新建状态
2.Ready，就绪状态，资源已分配，等待cpu
3.Running，运行状态
4.blocked，阻塞状态，等待资源或事件，不占cpu
5.terminated，终止状态，资源被回收

### 理解线程
为了支持并发，引入线程的概念。如果通过多进程来实现并发，那么将有比较大的上下文切换代价（除了cpu切换，主要是页表切换----内存地址转换）

### 理解协程
协程是一种特殊函数，用来实现协作式的多任务处理，提供了更加轻量的并发机制，进一步降低上下文切换开销，具有以下特点：
1.通常是异步的，并基于eventloop实现
2.程序自己来决定何时切换、创建、销毁，且开销较小，不涉及到用户态内核态切换（用户态、内核态指的是系统中两种不同的程序运行模式，内核态有更高权限级别，能执行底层操作并访问任何数据和资源，仅操作系统内核能进入）

### 进程与线程区别
1.进程是资源管理基本单位，线程是程序执行的基本单位，线程访问所属进程的资源
2.切换速度：线程更轻量，切换更快
3.系统开销：进程涉及到资源创建、回收，开销远大于线程

### 线程与协程区别
1.协程的调度由用户进行，线程由系统进行
2.协程运行在线程之中，一个线程可以有多个协程
3.协程不涉及用户态、内核态切换，共享线程资源，开销更小

### 并发与并行区别
1.并发是同一段时间，多个任务一起处理，但某一个时间片只有一个任务执行
2.并行基于多核处理器，同一时刻多个任务能一起执行

### 进程间通信方式
ps：线程内存是共享的，所以不谈通信
1.管道、命名管道
2.共享内存，通常用于需要高效共享大量数据的场景
3.socket通信
4.消息队列通信，如rabbitmq、redis、kafka
5.发送系统级别信号，通过系统发送给其他进程，如sigterm--进程结束信号，sigkill--强制结束进程信号

### 线程间同步方式
ps：同步主要是指资源的正确性和一致性，避免访问共享资源带来的冲突
1.临界区，指对多个线程的公有代码部分加锁得到一段同步代码，实现同一时间只有一个线程能访问
2.互斥锁（mutex），分为申请锁和释放锁两步，申请不到就无法继续执行。可以实现线程或进程（共享内存）间的同步
3.信号量，允许多个线程或进程同时访问，申请后-1，最大值为1即为互斥量
4.事件，通过事件通知来保持线程、进程同步

### 进程间同步方式
ps：进程间只要能通信，就能传递控制信息，也就能实现同步，判断自己该不该访问资源，重点是通信方式
1.信号量、互斥锁这些都可以放到共享内存，从而实现同步
2.进一步如zookeeper、redis、rabbitmq，只要能实现通信，就能让关键信息同步，例如利用redis实现分布式锁，key存在时其他客户端无法创建

### 死锁
死锁即多个进程（或线程）竞争资源引起的互相等待现象
出现条件：
1.资源的互斥
2.请求资源且不释放持有资源
3.无法强行剥夺资源
4.形成一个循环
解决办法：
1.预防：能预知资源就对资源预分配，允许强行剥夺资源来打破死锁，分层的资源分配来避免循环，提供机制动态监测是否可能引发死锁，避免进入不安全状态（银行家算法）
2.检测和恢复：检测是否发生死锁，恢复则是利用上面的死锁条件破除死锁
实际开发场景避免死锁：
1.锁超时
2.尽量避免多重锁互相嵌套
3.不同的锁只锁对应的对象，不混用
4.分配锁时注意分配后是否会进入不安全状态

### 进程调度策略
1.fifo，先来先服务
2.短作业优先
3.剩余时间优先
4.时间片均分
5.优先级调度


## 内存
### 分页
为了提高内存利用率，将内存分割成固定大小，进程访问内存时先访问页表，计算出实际内存的物理地址再访问。（实现虚拟内存，获取更大空间）
### 分段
内存分段是将内存划分为不同大小、用途的段并进行管理的技术，满足代码逻辑需求（如数据共享、数据保护）。一个程序可能包含代码段、数据段、堆栈段等。段的大小可以动态改变。
### 交换空间
物理磁盘上用来暂存内存页的空间。缓解物理内存不足的问题。
### 页替换算法
磁盘--->内存的替换算法
1.FIFO先进先出
2.NRU，最近未使用，对页置R、M位，分为4类，缺页时按类依次挑选，例如先从读写都未发生的的类中选，没有再继续
3.LRU，最近最少使用，记录每个页的最近使用时间，剔除时间最久的链表节点
4.最优算法，预测将来不会使用的页
### 虚拟内存
将物理内存和磁盘空间结合，采用部分加载的技术以提供更大的内存空间，同时通过将不同应用程序的虚拟地址隔离提高系统的安全性


## io多路复用
指同时监听多个输入和输出流的状态，在有数据到达时通知应用程序处理。使得单线程能同时处理多个io请求，提高系统并发性、减少资源占用。常用select、poll、epoll。
例如服务端同时处理监听socket来建立连接、处理已经连接的socket来读取数据，这时就能使用io多路复用。
### select、poll 和 epoll 之间的区别
1.select，时间复杂度o（n），无差别轮询，fd受到单个进程能打开的最大连接数限制
2.poll，和select没什么区别，但没有最大连接数的限制，用链表存fd
3.epoll（event poll），时间复杂度o（1），由主动轮询改为被动通知（回调）。支持ET（边缘触发），即数据没读完只要没变化下次就不会提示，提高并发性能。

## 常见io模型
io读分为两阶段: 数据拷贝到内核缓冲区，内核缓冲区拷贝到应用的内存地址空间
1.阻塞式
2.非阻塞式，不断轮询，直到数据就绪，开始二阶段拷贝
3.io多路复用，数据就绪，开始二阶段拷贝
4.异步io，完成后回调，整个过程都是非阻塞的
5.信号驱动，也是异步，不过是注册一个信号处理函数，通过通知何时可以开始io，并在函数中进行阻塞式的io操作，后半部分是阻塞的